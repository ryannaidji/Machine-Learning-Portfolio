{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5f6a22c",
   "metadata": {},
   "source": [
    "# Anonymization Techniques\n",
    "\n",
    "In this notebook, we will explore various techniques used to anonymize data, ensuring that personal and sensitive information is protected. Each section will cover a different technique, including definitions, purposes, and examples.\n",
    "\n",
    "\n",
    "## 1. Data Masking\n",
    "## 2. Data Pseudonymization\n",
    "## 3. Generalization\n",
    "## 4. Suppression\n",
    "## 5. Noise Addition\n",
    "## 6. Data Swapping\n",
    "## 7. Aggregation\n",
    "## 8. Tokenization\n",
    "## 9. Synthetic Data Generation\n",
    "## 10. Differential Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53800445",
   "metadata": {},
   "source": [
    "# 1. Data Masking\n",
    "\n",
    "**Definition**: Data masking involves replacing sensitive information with obscured values to protect privacy.\n",
    "\n",
    "**Example**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e99d4623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Patient ID     Name Masked Patient ID\n",
      "0  123456789    Alice        123XXXXX89\n",
      "1  987654321      Bob        987XXXXX21\n",
      "2  567890123  Charlie        567XXXXX23\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "data = {'Patient ID': ['123456789', '987654321', '567890123'], 'Name': ['Alice', 'Bob', 'Charlie']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Masking patient IDs\n",
    "df['Masked Patient ID'] = df['Patient ID'].apply(lambda x: x[:3] + 'XXXXX' + x[-2:])\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26834e1",
   "metadata": {},
   "source": [
    "**Advantages:**\n",
    "\n",
    "- Simple to implement\n",
    "- Effective at hiding specific pieces of sensitive data\n",
    "\n",
    "**Disadvantages:**\n",
    "\n",
    "- Can be reversible if the masking pattern is predictable\n",
    "- Limited protection of not combined with other techniques\n",
    "\n",
    "**Level of Security:** `MODERATE`\n",
    "\n",
    "- Effective for hiding specific data points but can be vulnerable if patterns are predictable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c56c82",
   "metadata": {},
   "source": [
    "## 2. Data Pseudonymization\n",
    "\n",
    "**Definition**: Pseudonymization replaces private identifiers with pseudonyms or fake identifiers.\n",
    "\n",
    "**Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3e54492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Employee ID     Name             Pseudonymized Employee ID\n",
      "0      E12345    Alice  f2afc7ee-c52f-441c-94df-aa18edd77d2b\n",
      "1      E98765      Bob  39f56b97-3ad6-4197-8b49-d3e515888cf4\n",
      "2      E56789  Charlie  319a3999-9758-43f7-b49a-de9e54973e22\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "data = {'Employee ID': ['E12345', 'E98765', 'E56789'], 'Name': ['Alice', 'Bob', 'Charlie']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Pseudonymizing employee IDs\n",
    "df['Pseudonymized Employee ID'] = [str(uuid.uuid4()) for _ in range(df.shape[0])]\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a7304f",
   "metadata": {},
   "source": [
    "**Advantages:**\n",
    "\n",
    "- Reduces the rish of re-identification\n",
    "- Can be reversed if necessary, maintaining data utility\n",
    "\n",
    "**Disadvantages:**\n",
    "\n",
    "- Potential for re-identification if pseudonyms are not managed securely\n",
    "- Requires careful management of pseudonym mapping\n",
    "\n",
    "**Level of Security:** `HIGH`\n",
    "\n",
    "- Provides a balance between data utility and privacy but requires secure management of pseudonym mappings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacf40ad",
   "metadata": {},
   "source": [
    "## 3. Generalization\n",
    "\n",
    "**Definition:** Generalization dilutes the granularity of data to make it less specific.\n",
    "\n",
    "**Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "252b1db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Income Income Range\n",
      "0   15000        0-30K\n",
      "1   45000       30-60K\n",
      "2   78000      60-100K\n",
      "3  120000     100-200K\n",
      "4  200000     100-200K\n"
     ]
    }
   ],
   "source": [
    "# Sample data\n",
    "data = {'Income': [15000, 45000, 78000, 120000, 200000]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Generalizing income into ranges\n",
    "df['Income Range'] = pd.cut(df['Income'], bins=[0, 30000, 60000, 100000, 200000, float('inf')], labels=['0-30K', '30-60K', '60-100K', '100-200K', '200K+'])\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b43f14d",
   "metadata": {},
   "source": [
    "**Advantages:**\n",
    "\n",
    "- Reduces the risk of re-identification by making data less specific\n",
    "- Simple to implement and understand\n",
    "\n",
    "**Disadvantages:**\n",
    "\n",
    "- Loss of data granularity can reduce data utility\n",
    "- Not effective if generalized ranges are too broad\n",
    "\n",
    "**Level of Security:** `MODERATE`\n",
    "\n",
    "- Effective for making data less specific but may reduce data utility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198d1104",
   "metadata": {},
   "source": [
    "## 4. Suppression\n",
    "**Definition:** Suppression involves removing sensitive information from the dataset.\n",
    "\n",
    "**Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "605c13be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name\n",
      "0    Alice\n",
      "1      Bob\n",
      "2  Charlie\n"
     ]
    }
   ],
   "source": [
    "# Sample data\n",
    "data = {'Name': ['Alice', 'Bob', 'Charlie'], 'Address': ['123 Main St', '456 Elm St', '789 Oak St']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Suppressing addresses\n",
    "df.drop(columns=['Address'], inplace=True)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c7e0ea",
   "metadata": {},
   "source": [
    "**Advantages:**\n",
    "\n",
    "- Completely removes sensitive information\n",
    "- Simple to implement\n",
    "\n",
    "**Disadvantages:**\n",
    "\n",
    "- Loss of data can significantly reduce data utility\n",
    "- Not applicable if the removed data is essential for analysis\n",
    "\n",
    "**Level of Security:** `HIGH`\n",
    "\n",
    "- Provides strong privacy protection but at the cost of data utility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff1a65d",
   "metadata": {},
   "source": [
    "## 5. Noise Addition\n",
    "**Definition:** Noise addition introduces random noise to the data to mask the original values.\n",
    "\n",
    "**Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbaddef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Student ID  Grade  Noisy Grade\n",
      "0           1     85    86.463928\n",
      "1           2     90    92.947898\n",
      "2           3     95    92.185015\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sample data\n",
    "data = {'Student ID': [1, 2, 3], 'Grade': [85, 90, 95]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Adding noise to grades\n",
    "noise = np.random.normal(0, 2, df.shape[0])  # Mean = 0, SD = 2\n",
    "df['Noisy Grade'] = df['Grade'] + noise\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051bbff8",
   "metadata": {},
   "source": [
    "**Advantages:**\n",
    "\n",
    "- Preserves data structure while adding privacy\n",
    "- Can be adjusted to balance privacy and data utility\n",
    "\n",
    "**Disadvantages:**\n",
    "\n",
    "- Too much noise can distort the data and reduce its utility\n",
    "- May not be suitable for all types of data\n",
    "\n",
    "**Level of Security:** `MODERATE TO HIGH`\n",
    "\n",
    "- Effective if noise is appropriately calibrated but can reduce data utility if overused"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019074a1",
   "metadata": {},
   "source": [
    "## 6. Data Swapping\n",
    "**Definition:** Data swapping involves exchanging values between records to disrupt direct relationships.\n",
    "\n",
    "**Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f2b042d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Customer ID Postal Code Swapped Postal Code\n",
      "0            1       12345               67890\n",
      "1            2       67890               12345\n",
      "2            3       54321               54321\n"
     ]
    }
   ],
   "source": [
    "# Sample data\n",
    "data = {'Customer ID': [1, 2, 3], 'Postal Code': ['12345', '67890', '54321']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Swapping postal codes\n",
    "df['Swapped Postal Code'] = df['Postal Code'].sample(frac=1).reset_index(drop=True)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63f8e0e",
   "metadata": {},
   "source": [
    "**Advantages:**\n",
    "\n",
    "- Maintains overall data distribution\n",
    "- Disrupts direct linkage between attributes\n",
    "\n",
    "**Disadvantages:**\n",
    "\n",
    "- Swapping can sometimes be detected and reversed\n",
    "- Not suitable for small datasets\n",
    "\n",
    "**Level of Security:** `MODERATE`\n",
    "\n",
    "- Effective for disrupting direct linkages but can be vulnerable to reverse engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9d1890",
   "metadata": {},
   "source": [
    "## 7. Aggregation\n",
    "\n",
    "**Definition:** Aggregation summarizes data to a level where individual data points are no longer distinguishable.\n",
    "\n",
    "**Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7be95b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Customer Type  Transaction Amount\n",
      "0     Corporate                 450\n",
      "1        Retail                 250\n"
     ]
    }
   ],
   "source": [
    "# Sample data\n",
    "data = {'Customer Type': ['Retail', 'Corporate', 'Retail', 'Corporate'], 'Transaction Amount': [100, 200, 150, 250]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Aggregating transaction amounts by customer type\n",
    "df_aggregated = df.groupby('Customer Type', as_index=False)['Transaction Amount'].sum()\n",
    "print(df_aggregated)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df0d856",
   "metadata": {},
   "source": [
    "**Advantages:**\n",
    "\n",
    "- Protects individual data points while providing useful insights\n",
    "- Reduces risk of re-identification\n",
    "\n",
    "**Disadvantages:**\n",
    "\n",
    "- Loss of individual-level detail\n",
    "- Not suitable for all types of analysis\n",
    "\n",
    "**Level of Security:** `HIGH`\n",
    "\n",
    "- Effective for protecting individual data points but reduces data granularity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b1d50c",
   "metadata": {},
   "source": [
    "## 8. Tokenization\n",
    "**Definition:** Tokenization replaces sensitive data elements with non-sensitive equivalents (tokens).\n",
    "\n",
    "**Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29fb6025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   User ID                Email  \\\n",
      "0        1    alice@example.com   \n",
      "1        2      bob@example.com   \n",
      "2        3  charlie@example.com   \n",
      "\n",
      "                                     Tokenized Email  \n",
      "0  ff8d9819fc0e12bf0d24892e45987e249a28dce836a85c...  \n",
      "1  5ff860bf1190596c7188ab851db691f0f3169c453936e9...  \n",
      "2  add7232b65bb559f896cbcfa9a600170a7ca381a036678...  \n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "data = {'User ID': [1, 2, 3], 'Email': ['alice@example.com', 'bob@example.com', 'charlie@example.com']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Tokenizing email addresses\n",
    "df['Tokenized Email'] = df['Email'].apply(lambda x: hashlib.sha256(x.encode()).hexdigest())\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0bb77f",
   "metadata": {},
   "source": [
    "**Advantages:**\n",
    "\n",
    "- Can be used to securely store and manage sensitive data\n",
    "- Tokens can be mapped back to original values if necessary\n",
    "\n",
    "**Disadvantages:**\n",
    "\n",
    "- Requires secure management of token mappings\n",
    "- Potential for token re-identification if mappings are exposed\n",
    "\n",
    "**Level of Security:** `HIGH`\n",
    "\n",
    "- Provides strong security but depends on the secure management of tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02456bcc",
   "metadata": {},
   "source": [
    "## 9. Synthetic Data Generation\n",
    "\n",
    "**Definition:** Synthetic data generation creates artificial data that has similar statistical properties to the original data but does not relate to real individuals.\n",
    "\n",
    "**Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2f4bb1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Health_Metric_1  Health_Metric_2  Health_Metric_3  Health_Metric_4  \\\n",
      "0        -0.430668         0.672873        -0.724280        -0.539630   \n",
      "1         0.211646        -0.843897         0.534794         0.825848   \n",
      "2         1.092675         0.409106         1.100096        -0.942751   \n",
      "3         1.519901        -0.773361         1.998053         0.155132   \n",
      "4        -0.453901        -2.183473         0.244724         2.591239   \n",
      "\n",
      "   Health_Metric_5  Condition  \n",
      "0        -0.651600          0  \n",
      "1         0.681953          1  \n",
      "2        -0.981509          0  \n",
      "3        -0.385314          0  \n",
      "4        -0.484234          1  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import pandas as pd\n",
    "\n",
    "# Generating synthetic health data\n",
    "X, y = make_classification(n_samples=100, n_features=5, random_state=42)\n",
    "df_synthetic = pd.DataFrame(X, columns=[f'Health_Metric_{i}' for i in range(1, 6)])\n",
    "df_synthetic['Condition'] = y\n",
    "print(df_synthetic.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069ce622",
   "metadata": {},
   "source": [
    "**Advantages:**\n",
    "\n",
    "- No risk of re-identification since data is not real\n",
    "- Usefull for testing and training ML models\n",
    "\n",
    "**Disadvantages:**\n",
    "\n",
    "- May not perfectly represent the original data\n",
    "- Can be challenging to generate realistic synthetic data\n",
    "\n",
    "**Level of Security:** `VERY HIGH`\n",
    "\n",
    "- Provides the highest level of privacy protection but depends on the quality of synthetic data generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a3255a",
   "metadata": {},
   "source": [
    "## 10. Differential Privacy\n",
    "\n",
    "**Definition:** Differential privacy adds random noise to data or query results to ensure that the output does not reveal much about any single individual's data.\n",
    "\n",
    "Differential privacy is similar to noise addition in that both techniques involve adding noise to the data to protect privacy. However, the key difference lies in how the noise is added. Differential privacy uses controlled and mathematically calculated noise based on a privacy budget ($\\epsilon$), ensuring formal privacy guarantees. This controlled noise addition ensures that the inclusion or exclusion of any single data point does not significantly affect the analysis outcome, making it nearly impossible to infer individual data.\n",
    "\n",
    "\n",
    "**Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0757981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   User ID  Location  Noisy Location\n",
      "0        1         5        3.738993\n",
      "1        2        15       33.893026\n",
      "2        3        25      -30.191876\n",
      "3        4        35       38.416218\n",
      "4        5        45       25.750632\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Sample data\n",
    "data = {'User ID': [1, 2, 3, 4, 5], 'Location': [5, 15, 25, 35, 45]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Adding Laplace noise for differential privacy\n",
    "epsilon = 0.1\n",
    "sensitivity = 1.0\n",
    "df['Noisy Location'] = df['Location'] + np.random.laplace(0, sensitivity / epsilon, df.shape[0])\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734f8756",
   "metadata": {},
   "source": [
    "**Advantages:**\n",
    "\n",
    "- Provides strong privacy guarantees\n",
    "- Allows useful data analysis while protecting individual privacy\n",
    "\n",
    "**Disadvantages:**\n",
    "\n",
    "- Complexity in implementation\n",
    "- May reduce data accuracy if not properly calibrated\n",
    "\n",
    "**Level of Security:** `VERY HIGH`\n",
    "\n",
    "- Provides strong privacy guarantees but requires careful implementation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
