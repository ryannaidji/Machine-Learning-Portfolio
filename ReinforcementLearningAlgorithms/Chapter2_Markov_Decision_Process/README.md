# Chapter 2: Markov Decision Process (MDP)

## Contents

1. [Markov Decision Process](./01_MDP.ipynb)
   - States, Actions, and Rewards
   - Transition Probabilities
   - Discount Factor
   - MDP Framework
